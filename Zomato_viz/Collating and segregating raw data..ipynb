{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79cf8928",
   "metadata": {},
   "source": [
    "We import pandas to deal with our data in the form of a dataframe.\n",
    "We import os to access the directories, sub directories and files in our systems.\n",
    "We import glob to retrive all files matching a certain pattern. This is used for getting all files of a specific city and collating them into one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b5516be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3694f020",
   "metadata": {},
   "source": [
    "Defining a List to store the paths for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aec5bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Folders_cities=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9571001d",
   "metadata": {},
   "source": [
    "Defining a rootdirectory for our os module to traverse through. \n",
    "destination folder holds the path to our folder that would store the clean collated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1e6c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdirectory='V:\\Zomato\\zomato_data'\n",
    "global destination_folder\n",
    "destination_folder=r'V:\\Zomato\\zomato_Clean_CityWise_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab4b2d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'V:\\\\Zomato'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(rootdirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94ed4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "global City"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456785cc",
   "metadata": {},
   "source": [
    "The below block of code would be doing the work of getting different files for specific city and merging them into one clean file for that specific city.\n",
    "Basically we are collating over **7000 files worth of data into 81 files for 81 different cities.**\n",
    "\n",
    "We traverse through our directories in a for loop, we store the paths for cities in our Folders_cities list.\n",
    "Go through the paths using another for loop and then for each city we merge all the files belonging to that city and append it to a dataframe.\n",
    "We perform some data cleaning and convert this updated dataframe to a .csv file and write it to our destination folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0754e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for subdirectory, directory, files in os.walk(rootdirectory):\n",
    "    for dirs in directory:\n",
    "        folder=os.path.join(subdirectory,dirs)\n",
    "        Folders_cities.append(folder)\n",
    "        City=dirs\n",
    "        for item in Folders_cities:\n",
    "            path=(item + '\\\\')\n",
    "            all_files = glob.glob(path + \"/*.csv\")\n",
    "            all_files_data_List=[]\n",
    "            for file_name in all_files:\n",
    "                df=pd.read_csv(file_name,index_col=None, header=0,delimiter='|')\n",
    "                all_files_data_List.append(df)\n",
    "            frame = pd.concat(all_files_data_List, axis=0, ignore_index=True)\n",
    "            frame1=frame.drop(['PAGE NO'], axis=1)\n",
    "            frame1['VOTES']=frame['VOTES'].replace([\"NEW\",\"Opening\",\"-\"],\"99999\",regex=True)\n",
    "            frame1['RATING']=frame['RATING'].replace([\"NEW\",\"Opening\",\"-\"],\"99999.99\",regex=True)\n",
    "            Clean_CityWise_data=(destination_folder + '\\\\')\n",
    "            Clean_CityWise_data=(Clean_CityWise_data + City + '.csv')\n",
    "            frame1.to_csv(Clean_CityWise_data, sep='|',header=True,index=False)\n",
    "\n",
    "        \n",
    "        \n",
    " #This block of code took around 1 hour to execute completly\n",
    "# to be exact 1 hour 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a89352",
   "metadata": {},
   "source": [
    "From the above block of code, we get collated data for all of the 81 cities. The top four cities with respect to size of data are the big four of India. Delhi, Bengaluru, Mumbai and Pune. \n",
    "Given the amount of numeric data, number of features, measures and dimensions I have tried to extract some insights using tableau.\n",
    "https://public.tableau.com/app/profile/vimal.rathod/viz/ZomatoMajorfour/Dashboard1\n",
    "\n",
    "\n",
    "Please read README.md for visualizations of all four cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d2a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
